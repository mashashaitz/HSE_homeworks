{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymorphy2 import MorphAnalyzer\n",
    "m = MorphAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import RegexpTokenizer\n",
    "\n",
    "tokenizer = RegexpTokenizer(r'\\w+')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(text):\n",
    "    tokens = tokenizer.tokenize(text.lower())\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ngrams(tokens, n=2, patterns=None, stoplist=[]):\n",
    "    tokens = list(filter(lambda x: x not in stoplist, tokens))\n",
    "    lemmas = [m.parse(t)[0].normal_form for t in tokens]\n",
    "    ngrams = []\n",
    "    for i in range(len(lemmas) - (n-1)):\n",
    "        ngram = lemmas[i:i+n]\n",
    "        tngram = tokens[i:i+n]\n",
    "        tags = [m.parse(t)[0].tag.POS for t in tngram]\n",
    "        if patterns is not None:\n",
    "            if patterns == ['VERB', 'NOUN'] and tags in patterns:\n",
    "                c = 0\n",
    "                for t in lemmas:\n",
    "                    if t == ngram[0]:\n",
    "                        c += 1\n",
    "                if c > 49 and ('accs' in m.parse(tokens[i+n])[0].tag or 'accs' in m.parse(tokens[i+n])[2].tag or 'accs' in m.parse(tokens[i+n])[1].tag):\n",
    "                    ngrams.append(tuple(ngram))\n",
    "            elif tags in patterns:\n",
    "                ngrams.append(tuple(ngram))\n",
    "        else:\n",
    "            ngrams.append(tuple(ngram))\n",
    "    return ngrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading UDPipe model: done.\n"
     ]
    }
   ],
   "source": [
    "!/Users/masha/Desktop/need_for_vyshka/P_for_Proga/python/udpipe-1.2.0-bin/bin-osx/udpipe --input horizontal --output conllu \\\n",
    "--tokenize --tag --parse \\\n",
    "/Users/masha/Desktop/need_for_vyshka/P_for_Proga/python/udpipe-1.2.0-bin/models/russian-syntagrus-ud-2.4-190531.udpipe \\\n",
    "< testset2.txt > testset2.conllu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.parse import DependencyGraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trees = []\n",
    "\n",
    "with open('testset2.conllu') as f:\n",
    "    parsed_sents = f.read().split('\\n\\n')\n",
    "\n",
    "    for sent in parsed_sents:\n",
    "        tree = [line for line in sent.split('\\n') if line and line[0] != '#']\n",
    "        trees.append('\\n'.join(tree))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(trees[1163])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col = []\n",
    "for i, tree in enumerate(trees):\n",
    "    try:\n",
    "        for tri in DependencyGraph(trees[i], top_relation_label='root').triples():\n",
    "            if tri[0][-1] == 'VERB' and 'obj' in tri[1] and tri[2][-1] == 'NOUN':\n",
    "                b = [m.parse(t)[0].normal_form for t in [tri[0][0], tri[2][0]]]\n",
    "                if b not in col:\n",
    "                    col.append(b)\n",
    "    except AssertionError:\n",
    "        continue\n",
    "    except TypeError:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('testset2.txt', 'r', encoding='utf8') as file:  \n",
    "    text = file.read()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "stop = stopwords.words('russian')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = normalize(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bigrams = get_ngrams(tokens, patterns=[['VERB', 'NOUN']], stoplist=stop)\n",
    "c = Counter()\n",
    "for n in bigrams:\n",
    "    c[n] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c.most_common(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.collocations import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bigram_measures = nltk.collocations.BigramAssocMeasures()\n",
    "finder2 = BigramCollocationFinder.from_documents([[m.parse(t)[0].normal_form for t in tokens]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "finder2.nbest(bigram_measures.likelihood_ratio, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "finder2.nbest(bigram_measures.pmi, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dice = finder2.score_ngrams(bigram_measures.dice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted([x for x in dice if x[1] != 1.0], key=lambda x: x[1], reverse=True)[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlog = []\n",
    "ndice = []\n",
    "npmi = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = 100\n",
    "while len(nlog) < 100:\n",
    "    for b in finder2.nbest(bigram_measures.likelihood_ratio, t):\n",
    "        if b not in nlog:\n",
    "            if b in col:\n",
    "                nlog.append(b)\n",
    "    t += 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(nlog)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = 100\n",
    "while len(npmi) < 100:\n",
    "    for b in finder2.nbest(bigram_measures.pmi, t):\n",
    "        if b not in npmi:\n",
    "            if b in col:\n",
    "                npmi.append(b)\n",
    "    t += 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(npmi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = 0\n",
    "while len(ndice) < 100:\n",
    "    if t == 0:\n",
    "        t2 = 100\n",
    "    else:\n",
    "        t2 = t+20\n",
    "    for b in sorted([x for x in dice if x[1] != 1.0], key=lambda x: x[1], reverse=True)[t:t2]:\n",
    "        if b[0] not in ndice:\n",
    "            if b[0] in col:\n",
    "                ndice.append(b[0])\n",
    "    if t == 0:\n",
    "        t = 100\n",
    "    else:\n",
    "        t += 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(ndice)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlog[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ndice[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "npmi[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gold = set(ndice) & set(npmi) & set(nlog)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('verb_coll.txt', 'r', encoding='utf8') as file:  \n",
    "    diction = file.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = []\n",
    "for i in diction:\n",
    "    ts = normalize(i.replace('\\n', '').split('\\t')[-1])\n",
    "    ls = [m.parse(t)[0].normal_form for t in ts]\n",
    "    if len(ls) < 3:\n",
    "        d.append(ls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gold = []\n",
    "for g in set(ndice) & set(npmi) & set(nlog):\n",
    "    print(g)\n",
    "    if g in d:\n",
    "        gold.append(g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
