{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>type</th>\n",
       "      <th>review</th>\n",
       "      <th>label</th>\n",
       "      <th>file</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>test</td>\n",
       "      <td>Once again Mr. Costner has dragged out a movie...</td>\n",
       "      <td>neg</td>\n",
       "      <td>0_2.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>test</td>\n",
       "      <td>This is an example of why the majority of acti...</td>\n",
       "      <td>neg</td>\n",
       "      <td>10000_4.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>test</td>\n",
       "      <td>First of all I hate those moronic rappers, who...</td>\n",
       "      <td>neg</td>\n",
       "      <td>10001_1.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>test</td>\n",
       "      <td>Not even the Beatles could write songs everyon...</td>\n",
       "      <td>neg</td>\n",
       "      <td>10002_3.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>test</td>\n",
       "      <td>Brass pictures (movies is not a fitting word f...</td>\n",
       "      <td>neg</td>\n",
       "      <td>10003_3.txt</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  type                                             review label  \\\n",
       "0           0  test  Once again Mr. Costner has dragged out a movie...   neg   \n",
       "1           1  test  This is an example of why the majority of acti...   neg   \n",
       "2           2  test  First of all I hate those moronic rappers, who...   neg   \n",
       "3           3  test  Not even the Beatles could write songs everyon...   neg   \n",
       "4           4  test  Brass pictures (movies is not a fitting word f...   neg   \n",
       "\n",
       "          file  \n",
       "0      0_2.txt  \n",
       "1  10000_4.txt  \n",
       "2  10001_1.txt  \n",
       "3  10002_3.txt  \n",
       "4  10003_3.txt  "
      ]
     },
     "execution_count": 260,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('imdb_master.txt', sep=',', engine='python')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/masha/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>review</th>\n",
       "      <th>label</th>\n",
       "      <th>tokens</th>\n",
       "      <th>neg</th>\n",
       "      <th>pos</th>\n",
       "      <th>unsup</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>test</td>\n",
       "      <td>mr costner dragged movie far longer necessary ...</td>\n",
       "      <td>0</td>\n",
       "      <td>[mr, costner, dragged, movie, far, longer, nec...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>test</td>\n",
       "      <td>example majority action film  generic boring  ...</td>\n",
       "      <td>0</td>\n",
       "      <td>[example, majority, action, film, , generic, b...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>test</td>\n",
       "      <td>first hate moronic rapper  couldnt act gun pre...</td>\n",
       "      <td>0</td>\n",
       "      <td>[first, hate, moronic, rapper, , couldnt, act,...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>test</td>\n",
       "      <td>even beatles could write song everyone liked  ...</td>\n",
       "      <td>0</td>\n",
       "      <td>[even, beatles, could, write, song, everyone, ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>test</td>\n",
       "      <td>brass picture  movie fitting word  really some...</td>\n",
       "      <td>0</td>\n",
       "      <td>[brass, picture, , movie, fitting, word, , rea...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   type                                             review  label  \\\n",
       "0  test  mr costner dragged movie far longer necessary ...      0   \n",
       "1  test  example majority action film  generic boring  ...      0   \n",
       "2  test  first hate moronic rapper  couldnt act gun pre...      0   \n",
       "3  test  even beatles could write song everyone liked  ...      0   \n",
       "4  test  brass picture  movie fitting word  really some...      0   \n",
       "\n",
       "                                              tokens  neg  pos  unsup  \n",
       "0  [mr, costner, dragged, movie, far, longer, nec...    1    0      0  \n",
       "1  [example, majority, action, film, , generic, b...    1    0      0  \n",
       "2  [first, hate, moronic, rapper, , couldnt, act,...    1    0      0  \n",
       "3  [even, beatles, could, write, song, everyone, ...    1    0      0  \n",
       "4  [brass, picture, , movie, fitting, word, , rea...    1    0      0  "
      ]
     },
     "execution_count": 261,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "import re\n",
    "from nltk.stem import WordNetLemmatizer \n",
    "from nltk.corpus import stopwords\n",
    "stoplist = stopwords.words('english')\n",
    "nltk.download('punkt')\n",
    "lemmatizer = WordNetLemmatizer() \n",
    "\n",
    "\n",
    "toks = []\n",
    "reviews = []\n",
    "for r in df['review']:\n",
    "    tokens = nltk.word_tokenize(r)\n",
    "    l = []\n",
    "    for t in tokens:\n",
    "        tnew = t.lower()\n",
    "        tnew = re.sub(r'[^\\w\\s]','',tnew)\n",
    "        if tnew not in stoplist:\n",
    "            l.append(lemmatizer.lemmatize(tnew))\n",
    "    toks.append(l)\n",
    "    reviews.append(' '.join(l))\n",
    "df['review'] = reviews\n",
    "df['tokens'] = toks\n",
    "\n",
    "\n",
    "df = df.drop(columns=['Unnamed: 0', 'file'])\n",
    "\n",
    "\n",
    "negs = []\n",
    "poss = []\n",
    "unsup = []\n",
    "ls = []\n",
    "for l in df['label']:\n",
    "    if l == 'neg':\n",
    "        negs.append(1)\n",
    "        poss.append(0)\n",
    "        unsup.append(0)\n",
    "        ls.append(0)\n",
    "    elif l == 'pos':\n",
    "        negs.append(0)\n",
    "        poss.append(1)\n",
    "        unsup.append(0)\n",
    "        ls.append(2)\n",
    "    elif l == 'unsup':\n",
    "        negs.append(0)\n",
    "        poss.append(0)\n",
    "        unsup.append(1)\n",
    "        ls.append(1)\n",
    "df['label'] = ls\n",
    "df['neg'] = negs \n",
    "df['pos'] = poss \n",
    "df['unsup'] = unsup \n",
    "\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df[df.type == 'train']\n",
    "df_test =  df[df.type == 'test']\n",
    "df_train = df_train[['review', 'tokens', 'label', 'pos', 'neg', 'unsup']]\n",
    "df_test = df_test[['review', 'tokens', 'label', 'pos', 'neg', 'unsup']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>tokens</th>\n",
       "      <th>label</th>\n",
       "      <th>pos</th>\n",
       "      <th>neg</th>\n",
       "      <th>unsup</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>25000</th>\n",
       "      <td>story man unnatural feeling pig  start opening...</td>\n",
       "      <td>[story, man, unnatural, feeling, pig, , start,...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25001</th>\n",
       "      <td>airport 77 start brand new luxury 747 plane lo...</td>\n",
       "      <td>[airport, 77, start, brand, new, luxury, 747, ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25002</th>\n",
       "      <td>film lacked something could nt put finger firs...</td>\n",
       "      <td>[film, lacked, something, could, nt, put, fing...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25003</th>\n",
       "      <td>sorry everyone    know supposed  art  film   w...</td>\n",
       "      <td>[sorry, everyone, , , , know, supposed, , art,...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25004</th>\n",
       "      <td>little parent took along theater see interior ...</td>\n",
       "      <td>[little, parent, took, along, theater, see, in...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  review  \\\n",
       "25000  story man unnatural feeling pig  start opening...   \n",
       "25001  airport 77 start brand new luxury 747 plane lo...   \n",
       "25002  film lacked something could nt put finger firs...   \n",
       "25003  sorry everyone    know supposed  art  film   w...   \n",
       "25004  little parent took along theater see interior ...   \n",
       "\n",
       "                                                  tokens  label  pos  neg  \\\n",
       "25000  [story, man, unnatural, feeling, pig, , start,...      0    0    1   \n",
       "25001  [airport, 77, start, brand, new, luxury, 747, ...      0    0    1   \n",
       "25002  [film, lacked, something, could, nt, put, fing...      0    0    1   \n",
       "25003  [sorry, everyone, , , , know, supposed, , art,...      0    0    1   \n",
       "25004  [little, parent, took, along, theater, see, in...      0    0    1   \n",
       "\n",
       "       unsup  \n",
       "25000      0  \n",
       "25001      0  \n",
       "25002      0  \n",
       "25003      0  \n",
       "25004      0  "
      ]
     },
     "execution_count": 263,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>tokens</th>\n",
       "      <th>label</th>\n",
       "      <th>pos</th>\n",
       "      <th>neg</th>\n",
       "      <th>unsup</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>mr costner dragged movie far longer necessary ...</td>\n",
       "      <td>[mr, costner, dragged, movie, far, longer, nec...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>example majority action film  generic boring  ...</td>\n",
       "      <td>[example, majority, action, film, , generic, b...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>first hate moronic rapper  couldnt act gun pre...</td>\n",
       "      <td>[first, hate, moronic, rapper, , couldnt, act,...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>even beatles could write song everyone liked  ...</td>\n",
       "      <td>[even, beatles, could, write, song, everyone, ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>brass picture  movie fitting word  really some...</td>\n",
       "      <td>[brass, picture, , movie, fitting, word, , rea...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review  \\\n",
       "0  mr costner dragged movie far longer necessary ...   \n",
       "1  example majority action film  generic boring  ...   \n",
       "2  first hate moronic rapper  couldnt act gun pre...   \n",
       "3  even beatles could write song everyone liked  ...   \n",
       "4  brass picture  movie fitting word  really some...   \n",
       "\n",
       "                                              tokens  label  pos  neg  unsup  \n",
       "0  [mr, costner, dragged, movie, far, longer, nec...      0    0    1      0  \n",
       "1  [example, majority, action, film, , generic, b...      0    0    1      0  \n",
       "2  [first, hate, moronic, rapper, , couldnt, act,...      0    0    1      0  \n",
       "3  [even, beatles, could, write, song, everyone, ...      0    0    1      0  \n",
       "4  [brass, picture, , movie, fitting, word, , rea...      0    0    1      0  "
      ]
     },
     "execution_count": 264,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12598050 words total, with a vocabulary size of 166195\n",
      "Max sentence length is 1923 words\n"
     ]
    }
   ],
   "source": [
    "all_training_words = []\n",
    "training_sentence_lengths = []\n",
    "for s in df_train['tokens']:\n",
    "    training_sentence_lengths.append(len(s))\n",
    "    for t in s:\n",
    "        all_training_words.append(t)\n",
    "TRAINING_VOCAB = sorted(list(set(all_training_words)))\n",
    "print(\"%s words total, with a vocabulary size of %s\" % (len(all_training_words), len(TRAINING_VOCAB)))\n",
    "print(\"Max sentence length is %s words\" % max(training_sentence_lengths))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4096662 words total, with a vocabulary size of 86080\n",
      "Max sentence length is 1713 words\n"
     ]
    }
   ],
   "source": [
    "all_test_words = []\n",
    "test_sentence_lengths = []\n",
    "for s in df_test['tokens']:\n",
    "    test_sentence_lengths.append(len(s))\n",
    "    for t in s:\n",
    "        all_test_words.append(t)\n",
    "TEST_VOCAB = sorted(list(set(all_test_words)))\n",
    "print('%s words total, with a vocabulary size of %s' % (len(all_test_words), len(TEST_VOCAB)))\n",
    "print('Max sentence length is %s words' % max(test_sentence_lengths))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2019-12-30 23:30:24--  https://s3.amazonaws.com/dl4j-distribution/GoogleNews-vectors-negative300.bin.gz\n",
      "R'esolution de s3.amazonaws.com (s3.amazonaws.com)... 52.216.84.157\n",
      "Connexion `a s3.amazonaws.com (s3.amazonaws.com)|52.216.84.157|:443... connect'e.\n",
      "requ^ete HTTP transmise, en attente de la r'eponse... 416 Requested Range Not Satisfiable\n",
      "\n",
      "    Le fichier a d'ej`a 'et'e compl`etement r'ecup'er'e ; rien `a faire.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget -c \"https://s3.amazonaws.com/dl4j-distribution/GoogleNews-vectors-negative300.bin.gz\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim import models\n",
    "word2vec_path = 'GoogleNews-vectors-negative300.bin.gz'\n",
    "word2vec = models.KeyedVectors.load_word2vec_format(word2vec_path, binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_SEQUENCE_LENGTH = 7\n",
    "EMBEDDING_DIM = 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 165885 unique tokens.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "tokenizer = Tokenizer(num_words=len(TRAINING_VOCAB), lower=True, char_level=False)\n",
    "tokenizer.fit_on_texts(df_train['review'].tolist())\n",
    "training_sequences = tokenizer.texts_to_sequences(df_train['review'].tolist())\n",
    "train_word_index = tokenizer.word_index\n",
    "print('Found %s unique tokens.' % len(train_word_index))\n",
    "train_cnn_data = pad_sequences(training_sequences, \n",
    "                               maxlen=MAX_SEQUENCE_LENGTH)\n",
    "test_sequences = tokenizer.texts_to_sequences(df_test['review'].tolist())\n",
    "test_cnn_data = pad_sequences(test_sequences, maxlen=MAX_SEQUENCE_LENGTH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(165886, 300)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "train_embedding_weights = np.zeros((len(train_word_index)+1, EMBEDDING_DIM))\n",
    "for word,index in train_word_index.items():\n",
    "    train_embedding_weights[index,:] = word2vec[word] if word in word2vec else np.random.rand(EMBEDDING_DIM)\n",
    "print(train_embedding_weights.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_average_word2vec(tokens_list, vector, generate_missing=False, k=300):\n",
    "    if len(tokens_list)<1:\n",
    "        return np.zeros(k)\n",
    "    if generate_missing:\n",
    "        vectorized = [vector[word] if word in vector else np.random.rand(k) for word in tokens_list]\n",
    "    else:\n",
    "        vectorized = [vector[word] if word in vector else np.zeros(k) for word in tokens_list]\n",
    "    length = len(vectorized)\n",
    "    summed = np.sum(vectorized, axis=0)\n",
    "    averaged = np.divide(summed, length)\n",
    "    return averaged\n",
    "\n",
    "def get_word2vec_embeddings(vectors, clean_comments, generate_missing=False):\n",
    "    embeddings = clean_comments['tokens'].apply(lambda x: get_average_word2vec(x, vectors, \n",
    "                                                                                generate_missing=generate_missing))\n",
    "    return list(embeddings)\n",
    "train_embeddings = get_word2vec_embeddings(word2vec, df_train, generate_missing=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\ntrain_embeddings = []\\nfor t in df_train['tokens'].tolist():\\n    vec = []\\n    for w in t:\\n        if w in word2vec:\\n            vec.append(word2vec[w])\\n        else: \\n            vec.append(np.random.rand(300))\\n        \\n    train_embeddings.append(np.divide(np.sum(vec, axis=0), len(vec)))\\n\""
      ]
     },
     "execution_count": 273,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "train_embeddings = []\n",
    "for t in df_train['tokens'].tolist():\n",
    "    vec = []\n",
    "    for w in t:\n",
    "        if w in word2vec:\n",
    "            vec.append(word2vec[w])\n",
    "        else: \n",
    "            vec.append(np.random.rand(300))\n",
    "        \n",
    "    train_embeddings.append(np.divide(np.sum(vec, axis=0), len(vec)))\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ConvNet(embeddings, max_sequence_length, num_words, embedding_dim, labels_index):\n",
    "    \n",
    "    embedding_layer = Embedding(num_words,\n",
    "                            embedding_dim,\n",
    "                            weights=[embeddings],\n",
    "                            input_length=max_sequence_length,\n",
    "                            trainable=False)\n",
    "    \n",
    "    sequence_input = Input(shape=(max_sequence_length,), dtype='int32')\n",
    "    embedded_sequences = embedding_layer(sequence_input)\n",
    "\n",
    "    convs = []\n",
    "    filter_sizes = [2,3,4,5,6]\n",
    "\n",
    "    for filter_size in filter_sizes:\n",
    "        l_conv = Conv1D(filters=200, kernel_size=filter_size, activation='relu')(embedded_sequences)\n",
    "        l_pool = GlobalMaxPooling1D()(l_conv)\n",
    "        convs.append(l_pool)\n",
    "\n",
    "\n",
    "    l_merge = concatenate(convs, axis=1)\n",
    "\n",
    "    x = Dropout(0.1)(l_merge)  \n",
    "    x = Dense(128, activation='relu')(x)\n",
    "    x = Dropout(0.2)(x)\n",
    "    preds = Dense(labels_index, activation='sigmoid')(x)\n",
    "\n",
    "    model = Model(sequence_input, preds)\n",
    "    model.compile(loss='binary_crossentropy',\n",
    "                  optimizer='adam',\n",
    "                  metrics=['acc'])\n",
    "    model.summary()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_names = ['pos', 'neg', 'unsup']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = df_train[label_names].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = train_cnn_data\n",
    "y_tr = y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_12 (InputLayer)           (None, 7)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_13 (Embedding)        (None, 7, 300)       49765800    input_12[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_47 (Conv1D)              (None, 6, 200)       120200      embedding_13[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_48 (Conv1D)              (None, 5, 200)       180200      embedding_13[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_49 (Conv1D)              (None, 4, 200)       240200      embedding_13[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_50 (Conv1D)              (None, 3, 200)       300200      embedding_13[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_51 (Conv1D)              (None, 2, 200)       360200      embedding_13[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_45 (Global (None, 200)          0           conv1d_47[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_46 (Global (None, 200)          0           conv1d_48[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_47 (Global (None, 200)          0           conv1d_49[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_48 (Global (None, 200)          0           conv1d_50[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_49 (Global (None, 200)          0           conv1d_51[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_8 (Concatenate)     (None, 1000)         0           global_max_pooling1d_45[0][0]    \n",
      "                                                                 global_max_pooling1d_46[0][0]    \n",
      "                                                                 global_max_pooling1d_47[0][0]    \n",
      "                                                                 global_max_pooling1d_48[0][0]    \n",
      "                                                                 global_max_pooling1d_49[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_12 (Dropout)            (None, 1000)         0           concatenate_8[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_11 (Dense)                (None, 128)          128128      dropout_12[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_13 (Dropout)            (None, 128)          0           dense_11[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_12 (Dense)                (None, 3)            387         dropout_13[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 51,095,315\n",
      "Trainable params: 1,329,515\n",
      "Non-trainable params: 49,765,800\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Embedding, Input, Conv1D, GlobalMaxPooling1D, concatenate, Dropout, Dense\n",
    "from keras.models import Model\n",
    "model = ConvNet(train_embedding_weights, MAX_SEQUENCE_LENGTH, len(train_word_index)+1, EMBEDDING_DIM, \n",
    "                len(list(label_names)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 25\n",
    "batch_size = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 67500 samples, validate on 7500 samples\n",
      "Epoch 1/25\n",
      "67500/67500 [==============================] - 93s 1ms/step - loss: 0.5311 - acc: 0.7519 - val_loss: 0.3636 - val_acc: 0.9983\n",
      "Epoch 2/25\n",
      "67500/67500 [==============================] - 98s 1ms/step - loss: 0.5149 - acc: 0.7526 - val_loss: 0.3142 - val_acc: 1.0000\n",
      "Epoch 3/25\n",
      "41370/67500 [=================>............] - ETA: 39s - loss: 0.4959 - acc: 0.7499"
     ]
    }
   ],
   "source": [
    "hist = model.fit(x_train, y_tr, epochs=num_epochs, validation_split=0.1, shuffle=True, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(test_cnn_data, batch_size=100, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = [2, 0, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_labels=[]\n",
    "for p in predictions:\n",
    "    prediction_labels.append(labels[np.argmax(p)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(df_test.label==prediction_labels)/len(prediction_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(df_test.label==prediction_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(prediction_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
