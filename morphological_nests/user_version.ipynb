{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import urllib.request\n",
    "import json\n",
    "from pymystem3 import Mystem\n",
    "m = Mystem()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "load efremova, find suffixes and preffixes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "elines = []\n",
    "with open('nefremova.txt', 'r', encoding='utf-8') as f:\n",
    "    for line in f:\n",
    "        elines.append(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "preffix = []\n",
    "suffix = []\n",
    "for i, line in enumerate(elines):\n",
    "    if '1. префикс' in line:\n",
    "        if '.\\n' not in elines[i-1]:\n",
    "            preffix.append(elines[i-1].replace('-\\n', ''))\n",
    "    elif '1. суффикс' in line:\n",
    "        if '.п.' not in elines[i-1]:\n",
    "            if '(' in elines[i-1]:\n",
    "                suf = re.findall('.*?\\(', elines[i-1])[0]\n",
    "            else:\n",
    "                suf = elines[i-1]\n",
    "            suf = suf.replace('-', '').replace(' ', '').replace('(', '').replace('\\n', '')\n",
    "            if suf not in suff:\n",
    "                suffix.append(suf)\n",
    "preffix.extend(['ть', 'ться', 'ся'])\n",
    "endings = ['ий', 'ый', 'ой', 'ая', 'ое', 'ие', 'а', 'я', 'ы', 'и', 'е', 'у', 'ю']"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "open morphodict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_object = open('nests_new1.json', 'r', encoding='utf-8')\n",
    "json_nests = json.load(file_object)\n",
    "file_object.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def root2rt(root):\n",
    "    rt = root.replace('\\n', '')\n",
    "    rt = rt.replace('j', '')\n",
    "    rt = rt.replace('I', '').replace('1', '').replace('2', '').replace('3', '')\n",
    "    rt = rt.replace('<i>', '').replace('</i>', '')\n",
    "    rt = rt.replace('(', '').replace(')', '')\n",
    "    if ' ' in rt:\n",
    "        rt = re.split(' ', rt)[0]\n",
    "    elif '/' in rt:\n",
    "        rt = re.split('/', rt)[-1]\n",
    "    return rt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "296907\n"
     ]
    }
   ],
   "source": [
    "idshnik = 0\n",
    "for n in json_nests:\n",
    "    for k in n.keys():\n",
    "        nest = n[k]\n",
    "        for r in nest:\n",
    "            if int(r['id']) > idshnik:\n",
    "                idshnik = int(r['id'])\n",
    "print(idshnik)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nprint(nest, root):\n",
    "    trees ={}\n",
    "    nr = 0\n",
    "    for n in nest.values():\n",
    "        nroot = []\n",
    "        for l in n:\n",
    "            if (\n",
    "                root == l['root'] or\n",
    "                l['root'].startswith(root + ' ') or\n",
    "                l['root'].endswith('/' + root)\n",
    "                ):\n",
    "                trees[l['root']] = [l['root']]\n",
    "                \n",
    "        for r in trees:\n",
    "            ts = [r]\n",
    "            for l in n[::-1]:\n",
    "                for t in ts:\n",
    "                    if t in l['non-ambiguous'] or t in l['ambiguous']:\n",
    "                        ts.append(l['root'])\n",
    "            trees[r] = ts\n",
    "        \n",
    "        for r in trees:\n",
    "            ts = []\n",
    "            for l in n:\n",
    "                if l['root'] in ts or l['root'] == r: \n",
    "                    for na in l['non-ambiguous']:\n",
    "                        if na not in ts:\n",
    "                            ts.append(na)\n",
    "                    for a in l['ambiguous']:\n",
    "                        if a not in ts:\n",
    "                            ts.append(a)\n",
    "            trees[r].extend(ts)\n",
    "            \n",
    "        for r in trees:\n",
    "            for l in n:\n",
    "                if l['root'] in trees[r]:\n",
    "                    string = ''\n",
    "                    for d in range(l['depth']):\n",
    "                        string += '\\t'\n",
    "                    string += l['root']\n",
    "                    print(string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_nod(n, idshnik):\n",
    "\n",
    "    \n",
    "    n2 = n\n",
    "    for e in endings:\n",
    "        if n2.endswith(e) and len(n2) - len(e) > 2:\n",
    "            n2 = n2[:(len(n2) - len(e))]\n",
    "\n",
    "\n",
    "    for jn in json_nests:\n",
    "\n",
    "\n",
    "        for root in jn:\n",
    "            rt2 = root2rt(root)\n",
    "            if len(rt2) > 4:\n",
    "                for e in endings:\n",
    "                    if rt2.endswith(e) and len(rt2) - len(e) > 2:\n",
    "                        rt2 = rt2[:(len(rt2) - len(e))] \n",
    "        if rt2 not in n2:\n",
    "            continue\n",
    "\n",
    "\n",
    "        for nest in jn.values():\n",
    "            for j, r in enumerate(nest[::-1]):\n",
    "                rt = root2rt(r['root'])\n",
    "                if len(rt) > 4:\n",
    "                    for e in endings:\n",
    "                        if rt.endswith(e) and len(rt) - len(e) > 2:\n",
    "                            rt = rt[:(len(rt) - len(e))]\n",
    "\n",
    "\n",
    "                if n2.startswith(rt) and n2 != rt:\n",
    "\n",
    "                    word1 = n\n",
    "                    mettype1 = 'suf'\n",
    "                    met1 = n[len(rt) - 1:]\n",
    "                    ambiguous1 = []\n",
    "                    non_ambiguous1 = []\n",
    "                    depth1 = r['depth'] + 1\n",
    "                    id1 = idshnik\n",
    "                        \n",
    "                        \n",
    "                    try:\n",
    "                        PoS = m.analyze(word1)[0]['analysis'][0]['gr'].split('=')[0].split(',')[0]\n",
    "                    except (KeyError, IndexError, BrokenPipeError):\n",
    "                        PoS = 'unknown'\n",
    "\n",
    "                    root1 = {'root': word1, 'mettype': mettype1, 'met': met1,\n",
    "                                  'ambiguous': ambiguous1, 'non-ambiguous': non_ambiguous1, \n",
    "                                  'depth': depth1,'id': id1, 'PoS': PoS}\n",
    "\n",
    "                    for r2 in nest[::-1]:\n",
    "                        if n in r2['ambiguous']:\n",
    "                            r['ambiguous'].append(n)\n",
    "                        elif n in r2['non-ambiguous']:\n",
    "                            if n not in r['ambiguous']:\n",
    "                                r['ambiguous'].append(n)\n",
    "                            r2['ambiguous'].append(n)\n",
    "                            r2['non-ambiguous'].remove(n)\n",
    "                    if n not in r['ambiguous']:\n",
    "                        r['non-ambiguous'].append(n)\n",
    "\n",
    "                    nest.insert(len(nest) - j, root1) \n",
    "\n",
    "\n",
    "                elif rt.endswith(n2) and n2 != rt:\n",
    "                    if n in ealls:\n",
    "                        ealls.remove(n)\n",
    "                    idshnik += 1\n",
    "\n",
    "                    word1 = n\n",
    "                    mettype1 = 'pref'\n",
    "                    met1 = n2[:len(n2) - len(rt)]\n",
    "                    ambiguous1 = []\n",
    "                    non_ambiguous1 = []\n",
    "                    depth1 = r['depth'] + 1\n",
    "                    id1 = idshnik\n",
    "                    idshnik += 1\n",
    "                        \n",
    "                    try:\n",
    "                        PoS = m.analyze(word1)[0]['analysis'][0]['gr'].split('=')[0].split(',')[0]\n",
    "                    except (KeyError, IndexError, BrokenPipeError):\n",
    "                        PoS = 'unknown'\n",
    "\n",
    "                    root1 = {'root': word1, 'mettype': mettype1, 'met': met1,\n",
    "                                  'ambiguous': ambiguous1, 'non-ambiguous': non_ambiguous1, \n",
    "                                  'depth': depth1,'id': id1, 'PoS': PoS}\n",
    "\n",
    "                    for r2 in nest[::-1]:\n",
    "                        if n in r2['ambiguous']:\n",
    "                            r['ambiguous'].append(n)\n",
    "                        elif n in r2['non-ambiguous']:\n",
    "                            if n not in r['ambiguous']:\n",
    "                                r['ambiguous'].append(n)\n",
    "                            r2['ambiguous'].append(n)\n",
    "                            r2['non-ambiguous'].remove(n)\n",
    "                    if n not in r['ambiguous']:\n",
    "                        r['non-ambiguous'].append(n)\n",
    "\n",
    "                    nest.insert(len(nest) - j, root1) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_word(n):\n",
    "    for jn in json_nests:\n",
    "        for nest in jn.values():\n",
    "            for r in nest:\n",
    "                if root2rt(r['root']) == root2rt(n):\n",
    "                    return jn\n",
    "    return {}"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "insert your word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "word = 'коньяк'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "о\n",
      "\tко\n",
      "\t\tкон\n",
      "\t\tконь\n",
      "\t\t\tконь\n",
      "\t\t\tконьяк\n",
      "\t\t\tконьяк\n",
      "\t\t\t\tконьяк\n"
     ]
    }
   ],
   "source": [
    "n = m.lemmatize(word)[0]\n",
    "nest = find_word(n)\n",
    "if nest == {}:\n",
    "    add_nod(n, idshnik)\n",
    "    nest = find_word(n)\n",
    "    nprint(nest, n)\n",
    "else:\n",
    "    nprint(nest, n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
